{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "DATA_PATH = \"../../data/\"\n",
    "\n",
    "books_data = pd.read_csv(f\"{DATA_PATH}/raw/books_data.csv\")\n",
    "cleaned_reviews = pd.read_csv(f\"{DATA_PATH}/cleaned_data/cleaned_reviews.csv\")\n",
    "\n",
    "with open(f\"{DATA_PATH}/embeddings/bert_embeddings.npy\", \"rb\") as f:\n",
    "    bert_embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212404, 384), (212404, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings.shape, books_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded the dataframe as cleaned_reviews\n",
    "# Filter out users with less than a minimum number of reviews\n",
    "MIN_REVIEWS = 2\n",
    "user_counts = cleaned_reviews['User_id'].value_counts()\n",
    "valid_users = user_counts[user_counts >= MIN_REVIEWS].index\n",
    "\n",
    "filtered_reviews = cleaned_reviews.copy()[cleaned_reviews['User_id'].isin(valid_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/5vmyzh215993g2001_cz3wjc0000gp/T/ipykernel_4862/3882211436.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  filtered_reviews['normalized_score'] = filtered_reviews.apply(lambda row: (row['review/score'] - user_stats.loc[row['User_id'], 'mean']) / user_stats.loc[row['User_id'], 'std'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Compute mean and std per user for rescaling\n",
    "user_stats = filtered_reviews.groupby('User_id')['review/score'].agg(['mean', 'std'])\n",
    "\n",
    "# Apply rescaling per user\n",
    "filtered_reviews['normalized_score'] = filtered_reviews.apply(lambda row: (row['review/score'] - user_stats.loc[row['User_id'], 'mean']) / user_stats.loc[row['User_id'], 'std'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_nan_norm_score = filtered_reviews[filtered_reviews['normalized_score'].isna()].User_id.unique()\n",
    "filtered_reviews = filtered_reviews[~filtered_reviews.User_id.isin(users_with_nan_norm_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where the key is the title and the value is its index in the books_data DataFrame\n",
    "title_to_index = {title: idx for idx, title in enumerate(books_data['Title'])}\n",
    "\n",
    "# Map the Title in filtered_reviews to its index in books_data\n",
    "filtered_reviews = filtered_reviews.copy()\n",
    "filtered_reviews['Title_Index'] = filtered_reviews['Title'].map(title_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by user and time\n",
    "filtered_reviews = filtered_reviews.sort_values(by=['User_id', 'review/time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003101, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69099/69099 [38:22<00:00, 30.01it/s]\n",
      "100%|██████████| 23033/23033 [12:48<00:00, 29.97it/s]\n",
      "100%|██████████| 23033/23033 [12:49<00:00, 29.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "MAX_REVIEWS = 10\n",
    "# We can either use the normalized score or the raw scores\n",
    "SCORE_COLUMN = \"normalized_score\"\n",
    "\n",
    "# Split the unique user_ids into train, validation and test sets\n",
    "train_users, temp_users = train_test_split(filtered_reviews['User_id'].unique(), test_size=0.4, random_state=42)\n",
    "valid_users, test_users = train_test_split(temp_users, test_size=0.5, random_state=42)\n",
    "\n",
    "def prepare_sequences(users, df):\n",
    "    sequences = []\n",
    "    for user in tqdm(users):\n",
    "        user_data = df[df['User_id'] == user]\n",
    "        \n",
    "        # Ensure that we keep only the most recent MAX_REVIEWS reviews\n",
    "        if len(user_data) > MAX_REVIEWS + 1:\n",
    "            user_data = user_data.iloc[-(MAX_REVIEWS + 1):]  # +1 to account for the query doc\n",
    "\n",
    "        title_indexes = user_data['Title_Index'].values[:-1]\n",
    "        scores = user_data[SCORE_COLUMN].values[:-1]\n",
    "        \n",
    "        mask = [1] * len(title_indexes) + [0] * (MAX_REVIEWS - len(title_indexes))\n",
    "        title_indexes = list(title_indexes) + [0] * (MAX_REVIEWS - len(title_indexes))\n",
    "        scores = list(scores) + [0] * (MAX_REVIEWS - len(scores))\n",
    "        query_id = user_data['Title_Index'].values[-1]\n",
    "        target = user_data[SCORE_COLUMN].values[-1]\n",
    "        \n",
    "        sequences.append([title_indexes, scores, mask, query_id, target])\n",
    "    return sequences\n",
    "\n",
    "\n",
    "\n",
    "train_sequences = prepare_sequences(train_users, filtered_reviews)\n",
    "valid_sequences = prepare_sequences(valid_users, filtered_reviews)\n",
    "test_sequences = prepare_sequences(test_users, filtered_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title_indexes, scores, mask, query_id, target = self.sequences[idx]\n",
    "        return torch.tensor(title_indexes, dtype=torch.long), \\\n",
    "               torch.tensor(scores, dtype=torch.float32), \\\n",
    "               torch.tensor(mask, dtype=torch.float32), \\\n",
    "               torch.tensor(query_id, dtype=torch.long), \\\n",
    "               torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "train_dataset = ReviewDataset(train_sequences)\n",
    "valid_dataset = ReviewDataset(valid_sequences)\n",
    "test_dataset = ReviewDataset(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use the raw scores, we change the prefix string to 'raw_score_'\n",
    "prefix = \"normalized_score_\"\n",
    "filepath_prefix = DATA_PATH + \"/datasets/\" + prefix\n",
    "\n",
    "torch.save(train_loader, f\"{filepath_prefix}train_loader.pth\")\n",
    "torch.save(valid_loader, f\"{filepath_prefix}valid_loader.pth\")\n",
    "torch.save(test_loader, f\"{filepath_prefix}test_loader.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([150003,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0]),\n",
       " tensor([0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor(62165),\n",
       " tensor(-0.7071))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UserBehaviorEncoder(nn.Module):\n",
    "    def __init__(self, embeddings, num_heads, output_dim, num_layers=1):\n",
    "        super(UserBehaviorEncoder, self).__init__()\n",
    "        \n",
    "        self.doc_emb_dim = embeddings.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embeddings).float(), padding_idx=0, freeze=True)\n",
    "        \n",
    "        # Embedding to transform scores to the same dimensionality as document embeddings\n",
    "        self.score_emb = nn.Linear(1, self.doc_emb_dim)\n",
    "        \n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.doc_emb_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Dense layer to produce final user behavior representation\n",
    "        self.fc = nn.Linear(self.doc_emb_dim, output_dim)\n",
    "\n",
    "    def forward(self, doc_indices, scores, attention_mask=None):\n",
    "        # Get the document embeddings using the indices\n",
    "        doc_embeddings = self.embedding(doc_indices)\n",
    "        \n",
    "        # Transform scores to embeddings\n",
    "        scores_emb = self.score_emb(scores.unsqueeze(-1)).squeeze(2)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined_emb = doc_embeddings + scores_emb\n",
    "\n",
    "        # Permute to match expected shape\n",
    "        combined_emb_permuted = combined_emb.permute(1, 0, 2)\n",
    "        \n",
    "        # Apply the transformer encoder\n",
    "        attended_values_permuted = self.transformer_encoder(\n",
    "            combined_emb_permuted,\n",
    "            src_key_padding_mask=(attention_mask == 0).bool()\n",
    "        )\n",
    "\n",
    "        # Permute the values back to (batch_size, sequence_length, embedding_dim)\n",
    "        attended_values = attended_values_permuted.permute(1, 0, 2)\n",
    "        \n",
    "        # Produce user behavior embedding\n",
    "        user_behavior_emb = attended_values.mean(dim=1)\n",
    "        \n",
    "        # Pass through a dense layer\n",
    "        user_behavior_rep = self.fc(user_behavior_emb)\n",
    "        \n",
    "        return user_behavior_rep\n",
    "\n",
    "class UserPreferenceRegressor(nn.Module):\n",
    "    def __init__(self, embeddings, num_heads, user_behavior_output_dim, predictor_hidden_dim, num_transformer_layers):\n",
    "        super(UserPreferenceRegressor, self).__init__()\n",
    "        \n",
    "        self.encoder = UserBehaviorEncoder(embeddings, num_heads, user_behavior_output_dim, num_layers=num_transformer_layers)\n",
    "        \n",
    "        # Define the predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(user_behavior_output_dim + embeddings.shape[1], predictor_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(predictor_hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, doc_indices, scores, attention_mask, new_doc_embedding):\n",
    "        user_behavior = self.encoder(doc_indices, scores, attention_mask)\n",
    "        combined = torch.cat([user_behavior, new_doc_embedding], dim=1)\n",
    "        return self.predictor(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "NUM_HEADS = 2  # for MultiHeadAttention\n",
    "OUTPUT_DIM = 128  # User behavior representation dimension\n",
    "HIDDEN_DIM = 256  # Predictor hidden layer dimension\n",
    "NUM_TRANSFORMER_LAYERS = 1\n",
    "\n",
    "# Initialize model\n",
    "model = UserPreferenceRegressor(bert_embeddings, NUM_HEADS, OUTPUT_DIM, HIDDEN_DIM, NUM_TRANSFORMER_LAYERS)\n",
    "model = model.to(device)  # Move model to device\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.4839\n",
      "Validation Loss: 0.4517\n",
      "Epoch [2/20], Train Loss: 0.4456\n",
      "Validation Loss: 0.4376\n",
      "Epoch [3/20], Train Loss: 0.4306\n",
      "Validation Loss: 0.4218\n",
      "Epoch [4/20], Train Loss: 0.4217\n",
      "Validation Loss: 0.4168\n",
      "Epoch [5/20], Train Loss: 0.4131\n",
      "Validation Loss: 0.4348\n",
      "Epoch [6/20], Train Loss: 0.4121\n",
      "Validation Loss: 0.4291\n",
      "Epoch [7/20], Train Loss: 0.3987\n",
      "Validation Loss: 0.4214\n",
      "Epoch [8/20], Train Loss: 0.3954\n",
      "Validation Loss: 0.4336\n",
      "Epoch [9/20], Train Loss: 0.3877\n",
      "Validation Loss: 0.4070\n",
      "Epoch [10/20], Train Loss: 0.4235\n",
      "Validation Loss: 0.4321\n",
      "Epoch [11/20], Train Loss: 0.4309\n",
      "Validation Loss: 0.4468\n",
      "Epoch [12/20], Train Loss: 0.4167\n",
      "Validation Loss: 0.4256\n",
      "Epoch [13/20], Train Loss: 0.4103\n",
      "Validation Loss: 0.3867\n",
      "Epoch [14/20], Train Loss: 0.3197\n",
      "Validation Loss: 0.4232\n",
      "Epoch [15/20], Train Loss: 0.3720\n",
      "Validation Loss: 0.3127\n",
      "Epoch [16/20], Train Loss: 0.3012\n",
      "Validation Loss: 0.2967\n",
      "Epoch [17/20], Train Loss: 0.2886\n",
      "Validation Loss: 0.3183\n",
      "Epoch [18/20], Train Loss: 0.3368\n",
      "Validation Loss: 0.4394\n",
      "Epoch [19/20], Train Loss: 0.4160\n",
      "Validation Loss: 0.4360\n",
      "Epoch [20/20], Train Loss: 0.3921\n",
      "Validation Loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=NUM_EPOCHS):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for idx, (title_indexes, scores, mask, query_id, target) in enumerate(train_loader):\n",
    "            title_indexes, scores, mask, query_id, target = title_indexes.to(device), scores.to(device), mask.to(device), query_id.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            new_doc_embedding = model.encoder.embedding(query_id).squeeze(1)\n",
    "            outputs = model(title_indexes, scores.unsqueeze(2), mask, new_doc_embedding)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(1), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for title_indexes, scores, mask, query_id, target in valid_loader:\n",
    "                title_indexes, scores, mask, query_id, target = title_indexes.to(device), scores.to(device), mask.to(device), query_id.to(device), target.to(device)\n",
    "                new_doc_embedding = model.encoder.embedding(query_id).squeeze(1)\n",
    "                outputs = model(title_indexes, scores.unsqueeze(2), mask, new_doc_embedding)\n",
    "                loss = criterion(outputs.squeeze(1), target)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(f\"Validation Loss: {val_loss/len(valid_loader):.4f}\")\n",
    "        \n",
    "# Call the training function\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212404/212404 [05:28<00:00, 645.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict_scores_for_all_books(model, embeddings, doc_indices, scores):\n",
    "    \"\"\"\n",
    "    Predict the scores for a user for all N books.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained UserPreferenceRegressor model.\n",
    "    - embeddings: The embeddings for all N books.\n",
    "    - doc_indices: A list of document indices representing user reviews.\n",
    "    - scores: A list of scores associated with the user reviews.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples with each tuple containing (book_id, predicted_score).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the doc_indices and scores to tensors\n",
    "    doc_indices_tensor = torch.tensor([doc_indices + [0] * (10 - len(doc_indices))], dtype=torch.long)\n",
    "    scores_tensor = torch.tensor([scores + [0.0] * (MAX_REVIEWS - len(scores))], dtype=torch.float).unsqueeze(-1)\n",
    "    \n",
    "    # Create an attention mask for valid reviews\n",
    "    attention_mask = [False] * len(doc_indices) + [True] * (MAX_REVIEWS - len(doc_indices))\n",
    "    attention_mask_tensor = torch.tensor([attention_mask])\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    # Loop over all book embeddings to predict the scores\n",
    "    for book_id in tqdm(range(embeddings.shape[0])):\n",
    "        # Get the book embedding tensor\n",
    "        new_doc_embedding_tensor = torch.tensor(embeddings[book_id]).unsqueeze(0)\n",
    "\n",
    "        # Use the model to predict the score\n",
    "        doc_indices_tensor, scores_tensor, attention_mask_tensor, new_doc_embedding_tensor = doc_indices_tensor.to(device), scores_tensor.to(device), attention_mask_tensor.to(device), new_doc_embedding_tensor.to(device)\n",
    "        predicted_score_tensor = model(doc_indices_tensor, scores_tensor, attention_mask_tensor, new_doc_embedding_tensor)\n",
    "        \n",
    "        # Convert tensor to scalar and append to all_predictions list\n",
    "        all_predictions.append(predicted_score_tensor.item())\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "preds = predict_scores_for_all_books(model, bert_embeddings, [36776, 99559], [5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71641</th>\n",
       "      <td>0.999039</td>\n",
       "      <td>Monty Python And The Holy Grail (Book): Monti Python ik den Holie Grailen (Bok)</td>\n",
       "      <td>The Monty Python team's first feature film is a mock-heroic tale set in Medieval Britain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20426</th>\n",
       "      <td>0.901003</td>\n",
       "      <td>White jacket: Or, The world in a man-of-war (The Works of Herman Melville, standard edition)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.891910</td>\n",
       "      <td>Munchkins Remember</td>\n",
       "      <td>Profiles the numerous men and women who played the citizens of Munchkinland, offering their perspectives on the creation of \"The Wizard of Oz,\" the film's stars, and their own lives before and after the film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78353</th>\n",
       "      <td>0.885720</td>\n",
       "      <td>The Annotated Wizard of Oz. The Wonderful Wizard of Oz</td>\n",
       "      <td>An annotated version of the classic tale of Dorothy's trip to Oz includes character sources, contemporary references, and inspirations behind the 1900 classic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27354</th>\n",
       "      <td>0.771891</td>\n",
       "      <td>An essay on the principle of population;: Or, A view of its past and present effects on human happiness</td>\n",
       "      <td>This book provides a student audience with the best scholarly edition of Malthus' Essay on Population. Written in 1798 as a polite attack on post-French revolutionary speculations on the theme of social and human perfectibility, it remains one of the most powerful statements of the limits to human hopes set by the tension between population growth and natural resources. Based on the authoritat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34005</th>\n",
       "      <td>0.753142</td>\n",
       "      <td>The Wonderful Wizard of Oz (Oxford World's Classics)</td>\n",
       "      <td>Published at the dawn of the twentieth century, The Wonderful Wizard of Oz (1900) immediately captivated children and adult readers alike. This new edition is the only one to include many of W.W. Denslow's original illustrations. The Introduction considers both the famous MGM film version and recent literary theory in a fascinating discussion of this timeless classic of children's literature. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80577</th>\n",
       "      <td>0.739985</td>\n",
       "      <td>White Jacket or The World in A Man-of-War</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15669</th>\n",
       "      <td>0.676415</td>\n",
       "      <td>Mad About the Oscars: 38 Best Picture Winners (and Losers!)</td>\n",
       "      <td>This is the first book of its kind. Aubrey Malone has gone back to the start of the Oscar ceremonies and discovered that mistakes have been made every year in the choice of what has been deemed “best” in the categories of acting, directing, producing and the subsidiary awards. He has identified all the great stars (Garbo, Montgomery Clift, Peter O’Toole, Barbara Stanwyck, etc.) who never held ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65203</th>\n",
       "      <td>0.657831</td>\n",
       "      <td>The Wizard of Oz &amp; Who he Was</td>\n",
       "      <td>Dorothy is transported over the rainbow in this picture book adaptation of the classic movie,The Wizard of Oz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120672</th>\n",
       "      <td>0.651185</td>\n",
       "      <td>The Pinecroft Thoroughbreds</td>\n",
       "      <td>Beautiful young Irish horsewoman Caitlin Cleary wanted to be a jockey but knew it wasn't possible for a woman in the early 20th century.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36503</th>\n",
       "      <td>0.637230</td>\n",
       "      <td>The prince with a hundred dragons</td>\n",
       "      <td>His name was Guy Gahairs Ethelnor Bulwinkle, and he didn't like having such a long name, because it was hard to write. He liked being called just plain Guy. He was a prince, and he didn't like that either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184017</th>\n",
       "      <td>0.632729</td>\n",
       "      <td>The Merry Adventures of Robin Hood (Illustrated Classic Editions, 4513)</td>\n",
       "      <td>For generations, readers have enjoyed classic literature. They have delighted in the romance of Jane Austen, thrilled at the adventures of Jules Verne, and pondered the lessons of Aesop. Introduce young readers to these familiar volumes with Great Illustrated Classics. In this series, literary masterworks have been adapted for young scholars. Large, easy-to-read type and charming pen-and-ink d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177599</th>\n",
       "      <td>0.613300</td>\n",
       "      <td>The Mammoth Book of Journalism: 101 Masterpieces from the Finest Writers and Reporters, Including Ernest Hemingway, George Orwell, Martha Gell (Mammoth Books)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189431</th>\n",
       "      <td>0.603604</td>\n",
       "      <td>The Classic Cartoons</td>\n",
       "      <td>Launched by Walt Disney in 1929 as a \"musical novelty\" series to complement his recent success with Mickey Mouse, the Silly Symphonies soon became much more. This line of delightfully innovative, animated cartoons ran for ten years and produced such classics as Three Little Pigs, The Tortoise and the Hare, Music Land, and The Old Mill. Silly Symphonies won every Academy Award presented to anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42073</th>\n",
       "      <td>0.586257</td>\n",
       "      <td>The Works of Oscar Wilde</td>\n",
       "      <td>The Collins Complete Works of Oscar Wilde is the only truly complete and authoritative single-volume edition of Oscar Wilde’s works.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174617</th>\n",
       "      <td>0.583883</td>\n",
       "      <td>Dictionary of Equine Terms</td>\n",
       "      <td>A reference for any horse lover, and especially for students of the horse, 4-H horse project members, vet tech students and teachers, writers, and illustrators. Terms encompass tack and equipment, parts of the horse, nutrition, behavior and training, medical and genetic issues, and anatomy. Entries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22808</th>\n",
       "      <td>0.583050</td>\n",
       "      <td>The Care and Breeding of the African Spurred Tortoise Geochelone Sulcata</td>\n",
       "      <td>This practical handbook covers the keeping and breeding of the large African spurred tortoise. It provides comprehensive information on diet, outdoor and indoor housing, distribution, and behaviour.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192687</th>\n",
       "      <td>0.569600</td>\n",
       "      <td>Whinnie The Lovesick Dragon</td>\n",
       "      <td>Whinnie the dragon falls in love with Alfred the knight, but she has trouble convincing him to accept her as a suitable romantic companion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195799</th>\n",
       "      <td>0.568983</td>\n",
       "      <td>Collected Essays Of Th Huxley</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187606</th>\n",
       "      <td>0.568807</td>\n",
       "      <td>The Knight's Castle: A Pop-Up Book</td>\n",
       "      <td>A small white mouse wanders into a castle where he sees a bat, a coat of arms, a dragon's head, and a shining knight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score  \\\n",
       "71641   0.999039   \n",
       "20426   0.901003   \n",
       "428     0.891910   \n",
       "78353   0.885720   \n",
       "27354   0.771891   \n",
       "34005   0.753142   \n",
       "80577   0.739985   \n",
       "15669   0.676415   \n",
       "65203   0.657831   \n",
       "120672  0.651185   \n",
       "36503   0.637230   \n",
       "184017  0.632729   \n",
       "177599  0.613300   \n",
       "189431  0.603604   \n",
       "42073   0.586257   \n",
       "174617  0.583883   \n",
       "22808   0.583050   \n",
       "192687  0.569600   \n",
       "195799  0.568983   \n",
       "187606  0.568807   \n",
       "\n",
       "                                                                                                                                                                 Title  \\\n",
       "71641                                                                                  Monty Python And The Holy Grail (Book): Monti Python ik den Holie Grailen (Bok)   \n",
       "20426                                                                     White jacket: Or, The world in a man-of-war (The Works of Herman Melville, standard edition)   \n",
       "428                                                                                                                                                 Munchkins Remember   \n",
       "78353                                                                                                           The Annotated Wizard of Oz. The Wonderful Wizard of Oz   \n",
       "27354                                                          An essay on the principle of population;: Or, A view of its past and present effects on human happiness   \n",
       "34005                                                                                                             The Wonderful Wizard of Oz (Oxford World's Classics)   \n",
       "80577                                                                                                                        White Jacket or The World in A Man-of-War   \n",
       "15669                                                                                                      Mad About the Oscars: 38 Best Picture Winners (and Losers!)   \n",
       "65203                                                                                                                                    The Wizard of Oz & Who he Was   \n",
       "120672                                                                                                                                     The Pinecroft Thoroughbreds   \n",
       "36503                                                                                                                                The prince with a hundred dragons   \n",
       "184017                                                                                         The Merry Adventures of Robin Hood (Illustrated Classic Editions, 4513)   \n",
       "177599  The Mammoth Book of Journalism: 101 Masterpieces from the Finest Writers and Reporters, Including Ernest Hemingway, George Orwell, Martha Gell (Mammoth Books)   \n",
       "189431                                                                                                                                            The Classic Cartoons   \n",
       "42073                                                                                                                                         The Works of Oscar Wilde   \n",
       "174617                                                                                                                                      Dictionary of Equine Terms   \n",
       "22808                                                                                         The Care and Breeding of the African Spurred Tortoise Geochelone Sulcata   \n",
       "192687                                                                                                                                     Whinnie The Lovesick Dragon   \n",
       "195799                                                                                                                                   Collected Essays Of Th Huxley   \n",
       "187606                                                                                                                              The Knight's Castle: A Pop-Up Book   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                            description  \n",
       "71641                                                                                                                                                                                                                                                                                                                         The Monty Python team's first feature film is a mock-heroic tale set in Medieval Britain.  \n",
       "20426                                                                                                                                                                                                                                                                                                                                                                                                               NaN  \n",
       "428                                                                                                                                                                                                     Profiles the numerous men and women who played the citizens of Munchkinland, offering their perspectives on the creation of \"The Wizard of Oz,\" the film's stars, and their own lives before and after the film  \n",
       "78353                                                                                                                                                                                                                                                   An annotated version of the classic tale of Dorothy's trip to Oz includes character sources, contemporary references, and inspirations behind the 1900 classic.  \n",
       "27354   This book provides a student audience with the best scholarly edition of Malthus' Essay on Population. Written in 1798 as a polite attack on post-French revolutionary speculations on the theme of social and human perfectibility, it remains one of the most powerful statements of the limits to human hopes set by the tension between population growth and natural resources. Based on the authoritat...  \n",
       "34005   Published at the dawn of the twentieth century, The Wonderful Wizard of Oz (1900) immediately captivated children and adult readers alike. This new edition is the only one to include many of W.W. Denslow's original illustrations. The Introduction considers both the famous MGM film version and recent literary theory in a fascinating discussion of this timeless classic of children's literature. ...  \n",
       "80577                                                                                                                                                                                                                                                                                                                                                                                                               NaN  \n",
       "15669   This is the first book of its kind. Aubrey Malone has gone back to the start of the Oscar ceremonies and discovered that mistakes have been made every year in the choice of what has been deemed “best” in the categories of acting, directing, producing and the subsidiary awards. He has identified all the great stars (Garbo, Montgomery Clift, Peter O’Toole, Barbara Stanwyck, etc.) who never held ...  \n",
       "65203                                                                                                                                                                                                                                                                                                    Dorothy is transported over the rainbow in this picture book adaptation of the classic movie,The Wizard of Oz.  \n",
       "120672                                                                                                                                                                                                                                                                         Beautiful young Irish horsewoman Caitlin Cleary wanted to be a jockey but knew it wasn't possible for a woman in the early 20th century.  \n",
       "36503                                                                                                                                                                                                     His name was Guy Gahairs Ethelnor Bulwinkle, and he didn't like having such a long name, because it was hard to write. He liked being called just plain Guy. He was a prince, and he didn't like that either.  \n",
       "184017  For generations, readers have enjoyed classic literature. They have delighted in the romance of Jane Austen, thrilled at the adventures of Jules Verne, and pondered the lessons of Aesop. Introduce young readers to these familiar volumes with Great Illustrated Classics. In this series, literary masterworks have been adapted for young scholars. Large, easy-to-read type and charming pen-and-ink d...  \n",
       "177599                                                                                                                                                                                                                                                                                                                                                                                                              NaN  \n",
       "189431  Launched by Walt Disney in 1929 as a \"musical novelty\" series to complement his recent success with Mickey Mouse, the Silly Symphonies soon became much more. This line of delightfully innovative, animated cartoons ran for ten years and produced such classics as Three Little Pigs, The Tortoise and the Hare, Music Land, and The Old Mill. Silly Symphonies won every Academy Award presented to anim...  \n",
       "42073                                                                                                                                                                                                                                                                              The Collins Complete Works of Oscar Wilde is the only truly complete and authoritative single-volume edition of Oscar Wilde’s works.  \n",
       "174617                                                                                                      A reference for any horse lover, and especially for students of the horse, 4-H horse project members, vet tech students and teachers, writers, and illustrators. Terms encompass tack and equipment, parts of the horse, nutrition, behavior and training, medical and genetic issues, and anatomy. Entries  \n",
       "22808                                                                                                                                                                                                            This practical handbook covers the keeping and breeding of the large African spurred tortoise. It provides comprehensive information on diet, outdoor and indoor housing, distribution, and behaviour.  \n",
       "192687                                                                                                                                                                                                                                                                      Whinnie the dragon falls in love with Alfred the knight, but she has trouble convincing him to accept her as a suitable romantic companion.  \n",
       "195799                                                                                                                                                                                                                                                                                                                                                                                                              NaN  \n",
       "187606                                                                                                                                                                                                                                                                                             A small white mouse wanders into a castle where he sees a bat, a coat of arms, a dragon's head, and a shining knight  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results = pd.Series(preds).sort_values(ascending=False)\n",
    "top_results.name = \"score\"\n",
    "top_results = pd.merge(top_results, books_data, left_index=True, right_index=True)[[\"score\",\"Title\",\"description\"]]\n",
    "top_results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36776</th>\n",
       "      <td>-1.556391</td>\n",
       "      <td>Harry Potter and The Sorcerer's Stone</td>\n",
       "      <td>Celebrate 20 years of Harry Potter magic! Harry Potter has never even heard of Hogwarts when the letters start dropping on the doormat at number four, Privet Drive. Addressed in green ink on yellowish parchment with a purple seal, they are swiftly confiscated by his grisly aunt and uncle. Then, on Harry's eleventh birthday, a great beetle-eyed giant of a man called Rubeus Hagrid bursts in with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99559</th>\n",
       "      <td>-1.190139</td>\n",
       "      <td>Harry Potter &amp; the Prisoner of Azkaban</td>\n",
       "      <td>Through classroom activities, wizard rock concerts, and organizations like the Harry Potter Alliance, Harry Potter fans are using creativity to positively impact the world. This collection of essays and interviews examines how playful fandom--from fanfiction to Muggle quidditch, cosplay, role-playing games, and even Harry Potter burlesque--not only reimagines the canon but also challenges cons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score                                   Title  \\\n",
       "36776 -1.556391   Harry Potter and The Sorcerer's Stone   \n",
       "99559 -1.190139  Harry Potter & the Prisoner of Azkaban   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                           description  \n",
       "36776  Celebrate 20 years of Harry Potter magic! Harry Potter has never even heard of Hogwarts when the letters start dropping on the doormat at number four, Privet Drive. Addressed in green ink on yellowish parchment with a purple seal, they are swiftly confiscated by his grisly aunt and uncle. Then, on Harry's eleventh birthday, a great beetle-eyed giant of a man called Rubeus Hagrid bursts in with...  \n",
       "99559  Through classroom activities, wizard rock concerts, and organizations like the Harry Potter Alliance, Harry Potter fans are using creativity to positively impact the world. This collection of essays and interviews examines how playful fandom--from fanfiction to Muggle quidditch, cosplay, role-playing games, and even Harry Potter burlesque--not only reimagines the canon but also challenges cons...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results.loc[[36776, 99559]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we have asked the model to recommend us books based on positive reviews for some Harry Potter books. We can notice the following:\n",
    "- The top results include many fantasy and magic related books, which is good.\n",
    "- The books we told the model we like have a very low score given by the model.\n",
    "\n",
    "The last obeservation shows that there's still room for improvement in the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('book_recommender')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98d862ff8fc58d25376058c3f52e24b7feee90c4848732fa1a0474216c84b788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
